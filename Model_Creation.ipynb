{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f19314d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 21, 2)             6         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 42)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               5504      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,800\n",
      "Trainable params: 6,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "164/164 [==============================] - 1s 2ms/step - loss: 2.3003 - accuracy: 0.1213\n",
      "Epoch 2/5\n",
      "164/164 [==============================] - 0s 2ms/step - loss: 2.2999 - accuracy: 0.1234\n",
      "Epoch 3/5\n",
      "164/164 [==============================] - 0s 2ms/step - loss: 2.2994 - accuracy: 0.1242\n",
      "Epoch 4/5\n",
      "164/164 [==============================] - 0s 2ms/step - loss: 2.2990 - accuracy: 0.1369\n",
      "Epoch 5/5\n",
      "164/164 [==============================] - 0s 2ms/step - loss: 2.2986 - accuracy: 0.1432\n",
      "Epoch 1/5\n",
      "164/164 [==============================] - 1s 2ms/step - loss: 2.2982 - accuracy: 0.1446\n",
      "Epoch 2/5\n",
      "164/164 [==============================] - 0s 3ms/step - loss: 2.2977 - accuracy: 0.1451\n",
      "Epoch 3/5\n",
      "164/164 [==============================] - 0s 2ms/step - loss: 2.2973 - accuracy: 0.1461\n",
      "Epoch 4/5\n",
      "164/164 [==============================] - 0s 2ms/step - loss: 2.2969 - accuracy: 0.1469\n",
      "Epoch 5/5\n",
      "164/164 [==============================] - 0s 2ms/step - loss: 2.2965 - accuracy: 0.1436\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\ENASSUK\\OneDrive - Ericsson\\Downloads\\Python_Code_For_GIThub\\HandGesture_Model\\assets\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Input\n",
    "from keras.layers.core import Dense,Flatten\n",
    "from keras.layers import InputLayer\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from  matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def create_dataset(img_folder):\n",
    "   \n",
    "    img_data_array=[]\n",
    "    class_name=[]\n",
    "   \n",
    "    for dir1 in os.listdir(img_folder):\n",
    "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
    "       \n",
    "            image_path= os.path.join(img_folder, dir1,  file)\n",
    "            image= cv2.imread( image_path, cv2.COLOR_BGR2RGB)\n",
    "            image=cv2.resize(image, (IMG_HEIGHT,IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
    "            image=np.array(image)\n",
    "            image = image.astype('float32')\n",
    "            image /= 255 \n",
    "            img_data_array.append(image)\n",
    "            class_name.append(dir1)\n",
    "    return img_data_array, class_name# extract the image array and class name\n",
    "\n",
    "if __name__=='__main__':\n",
    "\n",
    "    IMG_WIDTH = 21\n",
    "    IMG_HEIGHT = 2\n",
    "    img_folder=r'C:\\Users\\ENASSUK\\OneDrive - Ericsson\\Downloads\\Python_Code_For_GIThub\\HandGesture_Dataset\\images'\n",
    "\n",
    "    img_data, class_name =create_dataset(img_folder)\n",
    "    \n",
    "    target_dict={k: v for v, k in enumerate(np.unique(class_name))}\n",
    "    target_val=  [target_dict[class_name[i]] for i in range(len(class_name))]\n",
    "        \n",
    "    with open(r'C:\\Users\\ENASSUK\\OneDrive - Ericsson\\Downloads\\Python_Code_For_GIThub\\list_of_gestures.names','w+') as f:\n",
    "        for i, (key,values) in enumerate(target_dict.items()):\n",
    "            if i == len(target_dict) - 1:\n",
    "                f.write(str(key))\n",
    "            else:\n",
    "                f.write(str(key) + \"\\n\")\n",
    "    \n",
    "    \n",
    "    # Creating a simple deep learning model and compiling it\n",
    "\n",
    "    model=tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(IMG_WIDTH, IMG_HEIGHT)),\n",
    "            tf.keras.layers.Dense(2, activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "#             tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "#             tf.keras.layers.Dense(64, activation='softmax'),\n",
    "#             tf.keras.layers.Dense(32, activation='relu'),\n",
    "            tf.keras.layers.Dense(10, activation='softmax')\n",
    "        ])\n",
    "    \n",
    "    model.summary()\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.00001)\n",
    "    model.compile(optimizer= opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(x=np.array(img_data, np.float32), y=np.array(list(map(int,target_val)), np.float32), epochs=5)\n",
    "    history = model.fit(x=tf.cast(np.array(img_data), tf.float64), y=tf.cast(list(map(int,target_val)),tf.int32), epochs=5)\n",
    "    model.save(r'C:\\Users\\ENASSUK\\OneDrive - Ericsson\\Downloads\\Python_Code_For_GIThub\\HandGesture_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9479af85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0e1279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
